{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering - Item CF Example\n",
    "<img src=\"http://grouplens.org/site-content/uploads/ml-logo.png\"/>\n",
    "\n",
    "\n",
    "We are going to use the Movielens dataset to build a recommendation system. The dataset provides recommendations over 100,000 ratings from 1000 users on 1700 movies. Full data can be found [here](http://grouplens.org/datasets/movielens/100k/). Please go ahead and download/unzip the data before we continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You will have to possibly change where \"u.data\" and \"u.item\" can be found after downloading the dataset!\n",
    "\n",
    "rating_headers = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "movie_ratings = pd.read_csv('u.data',sep=\"\\t\",names=rating_headers)\n",
    "\n",
    "movie_headers = ['movie_id','title','release_date','video_release_date','imdb_url','unknown','action','adventure',\n",
    "                 'animation','childrens','comedy','crime','docu','drama','fantasy','film-noir','horror','musical',\n",
    "                 'mystery','romance','scifi','thriller','war','western']\n",
    "movie_titles = pd.read_csv('u.item',sep='|',names=movie_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We don't really care for the timestamp, so lets drop it\n",
    "movie_ratings.drop(\"timestamp\",axis=1,inplace=True)\n",
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For now, all we really care about are the movie_id and the title-- the first two columns\n",
    "movie_titles.drop(movie_titles.columns[2:movie_titles.shape[1]],axis=1,inplace=True)\n",
    "movie_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Okay, let's merge on the movie ratings and movie titles by movie id\n",
    "# This will give us a more easily readable dataset\n",
    "df = movie_ratings.merge(movie_titles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What do these ratings look like?\n",
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.hist('rating',bins=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gameplan\n",
    "\n",
    "\n",
    "Okay, so we have a full dataset. We want to now perform some item based collaborative filtering. Before we can do that, we should normalize the ratings globally, and then reform the data into a matrix of user x movie.\n",
    "\n",
    "**Quiz:** Why would we not want to normalize ratings per movie?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['rating_norm'] = df.rating - df.rating.mean()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.rating_norm.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Going to use pivot_table to create exactly the matrix we want of user x movie, where each entry is\n",
    "# the rating. We will 0 fill if there is no rating.\n",
    "user_item_df = df.pivot_table(values=\"rating_norm\",index=\"user_id\",columns=\"title\",fill_value=0)\n",
    "user_item_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many similarity metrics we could use to create a similarity matrix. The similarity matrix is a square matrix of item x item, where each entry is a metric with how similar the two items are.\n",
    "\n",
    "In this instance, we're going to define the similarity by column wise correlations. Now, for a given movie, we can look at what movies have the highest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_mat = pd.DataFrame(np.corrcoef(user_item_df,rowvar=0,bias=1),\n",
    "                        index=user_item_df.columns,\n",
    "                        columns=user_item_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_mat.loc[:,\"Toy Story (1995)\"].order(ascending=False)[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good! \"Youve watched Toy Story. You might also like Beauty and the Beast and Aladdin. (And maybe Apollo 13)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 1:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1** \n",
    "\n",
    "If you create a similarity matrix using vector cosine similarity rather than correlation, how do the top 10 \"similar\" movies for \"Toy Story (1995)\" change? Do they make sense?\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/math/7/0/6/706e3fbc6408ba68798bc970fc8a1fc6.png\"/>\n",
    "\n",
    "Given two movies `a` and `b`, you could compute this quantity as:\n",
    "```\n",
    "a.dot(b)/( np.linalg.norm(a) * np.linalg.norm(b) )\n",
    "```\n",
    "Hint: Think about how you could make this into a matrix operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at movie number 10. You would definitely want a hybrid approach here!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2**\n",
    "\n",
    "We are going to go back to using the correlation matrix now. Let's do some predictions for user 224. (i.e. You will want to use the Pandas \"loc\" function to access the _label_ 224, and not the _index_ 224. [More here](http://pandas.pydata.org/pandas-docs/stable/indexing.html)\n",
    "\n",
    "\n",
    "What are the top 10 movies that user 224 liked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3**\n",
    "\n",
    "Now, we are going to recommend user 224 some movies! The simplest way to get a set of recommended movies is to take the dot product of user_224 with our correlation matrix.\n",
    "```\n",
    "user_224_recs = user_224_series.dot( corr_mat )\n",
    "```\n",
    "\n",
    "What are the top 10 movies we would recommend user 224?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4**\n",
    "\n",
    "This is hard to visualize if our item based collaborative filtering is working well or not. Let's use seaborn to plot out a scatter of the items they rated, and our predictions for those items.\n",
    "```\n",
    "sb.regplot( user_224_series, user_224_recs )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good. We can ignore the actual numbers, but look at the trend. Roughly speaking, our predictions correlate well with their actually posted reviews. Now to be more accurate, we would have to run cross validation tests to confirm our recommendation engine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2:\n",
    "\n",
    "Recall the previous lecture's example on SVD. This time, use TruncatedSVD from the sklearn.decomposition module in order to decompose our data matrix of user x movie (where each item is the normalized rating).\n",
    "\n",
    "* Use TruncatedSVD to fit_transform our data matrix into a reduced matrix.\n",
    "* Plot the cumulative sum of explained\\_variance\\_ratio\\_.\n",
    "* Plot horizontal bargraphs of the first 8 components. What are the weights of the top 10 movies for each of these components?\n",
    "* Reconstruct the matrix using the svd.inverse_transform function and pass in your reduced matrix. This is equivalent to the following operation: reduced\\_matrix.dot( svd.components\\_ ). What are the top 10 recommendations for user 224?\n",
    "* Plot using sb.regplot user 224's ratings as well as the new recommendations for user 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 3 (Optional):\n",
    "\n",
    "\n",
    "The SVD method does not work as well when the matrix is very sparse (like now). Most recommendation systems instead try to model users and movies along some hidden feature space. The problem is having to solve for both some matrix X (user to feature) and some matrix Y (feature to movie). This can be solved using alternating least squares.\n",
    "\n",
    "Rough procedure, for N iterations:\n",
    "* Fix X. Solve for Y.\n",
    "* Fix Y. Solve for X.\n",
    "\n",
    "The following blog post has an example of alternative least squares solution. Try writing a version to solve and recommend based on the post:\n",
    "\n",
    "http://bugra.github.io/work/notes/2014-04-19/alternating-least-squares-method-for-collaborative-filtering/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
